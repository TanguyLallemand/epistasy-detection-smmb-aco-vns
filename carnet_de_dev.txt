
Pour demarrer le programm ./smmb_aco ../toy_dataset/genotype_toy_dataset.txt ../toy_dataset/phenotype_toy_dataset.txt

Attention les launch doivent avoir en comment l ensemble de l explication des parametres

chemins a changer:
boost folder dans le makefile


changer la solution cradot du -48 dans le file_parsing.cpp
(code ascii tout ça tout ça)
pour le moment on garde car on veut du fonctionnel mais faudrais dans l'idéal trouver mieux <3

changer la seed pour le sampling

faire une hashtable pour stocker les résultats des test (mem_ant)
chaque snp sera une clef et aura une liste de résultats associés
ajouter plus de flexibilite, genre le fichier des paramteres peut bouger
parallelisation a regarder, ne pas mettre le nbr de thread dans les parametres ou en dur dans le c++. On le met dans le launch_smmb_aco


fichiers d entres:
nom des variables entre virgules, autant de lignes que d individus et autant d ecolonnes que de variables et en plus le fichier des phenotypes
On fait du random sur tout sauf les deux variables du pattern d epistasie sur les quels ont fait de la rgression logistique. on simule X1 et X2. on a 3 valuers 0,1,2, donc 9 combianaisons possibles. Etant donne le modèle de regression, le calcul avec et Z>0.5. on en a par exemple 6 malade et 3 malade et apres on veut 5000 malades qu on prends dans les 6 configs et 3000 malades qu on prends dans les 3 configs

z= alpha + beta_1 * X1 + beta_2 * X2 + beta_12 * X1 * X2

pr = 1/ 1+exp(z)
si pr >0.5 alors malade sinon sain




fusionner les mem_a dans mem (globale) puis
    pour mettre a jour tau : //DONE
        pour X1 : _tau(X1) = (1 - rho) * _tau(X1) + _lambda * stat //DONE
        on boucle pour toutes les valeurs de stats dans mem //DONE
explication de l algo dans la publi

L’algorithme SMMB est une approche originale ; c’est la première variation stochastique proposée
pour le calcul d’une couverture de Markov : de multiples couvertures sont calculées sur des versions
perturbées du jeu de données, obtenues par échantillonnage des variables. Une couverture "consensus"
est ensuite construite. Pour assurer le passage à l’échelle requis par les études d’association génétique,
et ne pas biaiser l’apprentissage des CM en y incorporant une variable fortement dépendante avec lephénotype, la méthode SMMB se démarque des autres approches en ajoutant des groupes de variables
à la CM en cours de construction, au lieu d’ajouter les variables une à une.
L’algorithme SMMB-ACO permet de restreindre encore l’espace de recherche des combinaisons de
variables explorées. Dans ce cadre, un échantillon de variables est assigné à chacune des fourmis, qui
en apprend une couverture de Markov. A tous les niveaux de l’algorithme SMMB, l’échantillonnage
des variables est réalisé selon une loi uniforme. Dans SMMB-ACO, l’échantillonnage est guidé au
moyen d’une distribution de probabilité, calculée grâce à une stratégie d’optimisation de type colonie
de fourmis.

mardi 16 octobre, 166min smmb_aco



/*
FROM COURS DE SINOQUET
//attention k est different de _subset_size
output: un ensemble de couvertures de Markov sous optimales

MB_s<- ensemble non_vide
_tau = tau_0 // attention c'est une copie de vecteur ici
Pour i allant de 1 a _n_it
    P <- Calculer distribution de probabilite(_tau, _eta,_alpha_phero,_beta_phero);// ca a un rapport ac cette histoire de curseur
    pour j allant de 1 a _n_ants//La on fait travailler les fourmis //à parralelise, elle a dis de le faire, avec openMP, elle va nous donner les 2 lignes pour le faire
        _genos_matrix_subset = echantilloné(P, _genos_matrix, _subset_size )
        memoire_fourmis = ensemble_vide;
        MB_fourmis = learnMB(_genos_matrix_subset, phenos_matrix, k, _n_it_n, _alpha_stat, memoire_fourmis, P);
    fin pour
    memoire = ensemble vide
    pour a allant de 1 à _n_ants
        ajouter à memoire la memoire_fourmis;
        si MB_fourmi non vide alors MB_s(qui est un ensemble d'ensemble) = MB_s union MB_fourmi;
    finpour
    _tau = mise_a_jour_taux_de_pheromone(memoire, _rho, _lambda)
finpour
procedure de post traitement de MB_s // la prof ne veut pas detaille, ca depend comment on prend le projet, elle nous donnera un cahier des charges

//retourne une couverture sous optimale eventuellement vide
FONCTION learn_MB()

MB_fourmis = ensemble vide;
MB_modified = true;
j = 0;

//On entre dans la phase forward, ca permet d'éliminer des variables de la MB
tant que (MB_modified == true /*on est des barbus donc on met juste MB_modified */ or ( !empty(MB_fourmis) and j<n_it_n))
    MB_modified = false; //pour briser le prochain tour de boucle
    S = echantilloné(P, _genos_matrix_subset, k )
    s = argument qui maximise sur l'ensemble s' inclus ou égale à S (je considere toutes les combinaisons non vides possibles dans S ). Le truc qui est maximise c'est score d'association(s', _phenos_matrix, MB_fourmis, memoire_fourmis)
    si p_valeur(s)<_alpha_stat //rejet de l hypothese d'independance donc si on rejette on est en dependance ce qu on veut
    alors
        MB_fourmis = MB_fourmis union s
        MB_modified = true
        backward_phase(MB_fourmis, _phenos_matrix, _alpha_stat)
    finsi
    j++
fintantque
return MB_fourmis

procedure backward(MB, T, alpha)
{
    pour tout x element de MB
        pour toute combinaison S non_vides inclus dans MB
            realiser le test d'independance entre X et T conditionnellement a S_0
            Si p_valeur>global_alpha//H_0: independance
            alors
            MB <- MB\{x} //a gerer en liste
            break
}


*/

Le 20/11
La Simulation naive:
Les coefficients alpha beta1 beta2 et beta12 sont constant et ca determine une condition sous laquelle on simule les fichiers
On doit simuler 3 conditions

pattern d epistasie de taille 2 -> 2 SNP causaux  (x1,x2) -> {0,1,2} * {0,1,2}

y = alpha + beta_1*x_1 + beta_2*x_2 + beta_1_2 * x_1 *x_2
pr = 1 / (1+exp(-y))
si pr > 0.5 -< malade 1
    =< non malade 0

9 combinaisons a rendent malades {(0,1),(1,0),(1,1)}

A propos des tables de contingences:
Il faut compter le nombre de cases qui ne sont pas reliable mais pas cut le test
